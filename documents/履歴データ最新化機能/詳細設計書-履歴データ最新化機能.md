基本仕様書に基づき、**詳細設計書（Detailed Design Document）** を作成します。

この設計書では、`RakutenData` クラスにおけるメモリ内データ蓄積ロジックと、`RealtimeTrader` 停止時にそれをCSVファイルへ安全にマージ・保存するための具体的な実装仕様を定義します。

-----

# 詳細設計書: 履歴データ最新化機能

**プロジェクト:** StockAutoV3  
**作成日:** 2025/11/25  
**バージョン:** 1.0  
**実装ファイル:**

1.  `src/realtrade/rakuten/rakuten_data.py`
2.  `src/realtrade/cerebro_factory.py`
3.  `src/realtrade/run_realtrade.py`

## 1\. クラス設計変更

### 1.1. `RakutenData` (`src/realtrade/rakuten/rakuten_data.py`)

リアルタイムデータの蓄積と、ファイルへの書き込み責務を追加する。

#### 変更点: `__init__`

  * **引数追加:** `save_file: str = None`
      * データの保存先ファイルパスを受け取る。
  * **属性追加:**
      * `self.save_file`: 保存先パスを保持。
      * `self._new_bars`: `list[dict]`
          * 確定したバーデータを蓄積するバッファ。

#### 変更点: `_load` メソッド

  * `BarBuilder` から `completed_bar` (dict) が返された際、それを `self._new_bars` に追加するロジックを挿入する。
  * **データ構造:** `BarBuilder` の出力辞書 (`timestamp`, `open`, `high`, `low`, `close`, `volume`) に準拠。

#### 新規メソッド: `save_history()`

  * **概要:** メモリ上の `_new_bars` を既存の CSV ファイルにマージして保存する。
  * **ロジック詳細:**
    1.  `self._new_bars` が空であれば、ログを出力して終了する。
    2.  `self._new_bars` を `pandas.DataFrame` に変換する。
          * カラム: `datetime`, `open`, `high`, `low`, `close`, `volume`, `openinterest`
          * `openinterest` は 0 で埋める。
    3.  既存ファイル (`self.save_file`) の存在確認:
          * **存在する場合:** `pd.read_csv` で読み込む。
          * **存在しない場合:** 空の DataFrame を作成する。
    4.  **マージと重複排除:**
          * 既存DF と 新規DF を `pd.concat` で結合。
          * `datetime` カラムをキーに `drop_duplicates(keep='last')` を実行（再起動などで重複データが発生した場合、最新を優先）。
          * `datetime` で昇順ソート (`sort_values`)。
    5.  **保存:**
          * `to_csv` で書き込み。`index=False`。
          * 書き込み成功後、`self._new_bars` をクリアする。
          * [INFO] ログを出力: "保存完了: {ファイル名} (+{新規件数}件)"

### 1.2. `CerebroFactory` (`src/realtrade/cerebro_factory.py`)

`RakutenData` のインスタンス化時に、正しい保存先パスを渡すように変更する。

#### 変更点: `create_instance` メソッド

  * **ロジック:**
      * 既存の履歴データ読み込みロジック (`glob` で `latest_file` を取得する部分) を流用する。
      * `latest_file` が見つかった場合、そのパスを `RakutenData` の `save_file` 引数に渡す。
      * 見つからなかった場合（初回起動時など）、新規ファイルパスを生成して渡す。
          * 命名規則: `os.path.join(self.data_dir, f"{symbol}_{compression}m_{year}.csv")`
          * `year` は `datetime.now().year` を使用。

### 1.3. `RealtimeTrader` (`src/realtrade/run_realtrade.py`)

システム停止時に、全データフィードの保存メソッドを呼び出すトリガーを追加する。

#### 変更点: `stop` メソッド

  * **ロジック:**
      * `self.cerebro_instances` リストを走査する。
      * 各 Cerebro インスタンスのデータフィード (`cerebro.datas`) をループする。
      * データフィードが `save_history` メソッドを持っている場合（`hasattr` チェック）、それを実行する。
      * この処理は、`self.connector.stop()` などのリソース開放処理の**前**に行う。

## 2\. データフロー設計

### 2.1. 通常稼働時 (09:00 - 15:30)

1.  **Tick受信:** `ExcelConnector` -\> `RakutenData`
2.  **バー生成:** `RakutenData` -\> `BarBuilder` -\> `completed_bar` (dict)
3.  **蓄積:** `completed_bar` -\> `RakutenData._new_bars` (List append)
      * *注: この時点ではディスクI/Oは発生させない（パフォーマンス維持のため）。*

### 2.2. 停止処理時 (15:30)

1.  `run_realtrade.py` の `main` ループが市場クローズを検知。
2.  `trader.stop()` を呼び出す。
3.  `trader.stop()` が各 `RakutenData.save_history()` を呼び出す。
4.  `RakutenData` が CSV を読み込み、メモリデータを結合し、ディスクに書き戻す。
5.  保存完了後、プロセス（またはインスタンス）が破棄される。

## 3\. エラーハンドリングと安全性

### 3.1. CSV書き込みエラー

  * **リスク:** ディスク容量不足、ファイルロック（Excelで開いている等）による書き込み失敗。
  * **対策:**
      * `save_history` 内を `try...except` で囲む。
      * エラー時は [ERROR] ログを出力するが、**プロセスの停止処理自体は中断しない**（他のリソース開放を優先する）。
      * 致命的なデータ損失を防ぐため、書き込み前に一時ファイル (`.tmp`) に書き出し、成功したらリネームする方式（Atomic Write）が理想だが、今回は実装の簡易さを優先し、直接上書きとしつつ、バックアップ（`.bak`）を作成するロジックを推奨する。

### 3.2. データ型の不整合

  * **リスク:** 既存CSVの数値カラムに文字列が混入している、日付フォーマットが異なるなど。
  * **対策:**
      * `pd.read_csv` 時に `parse_dates=['datetime']` を指定し、型を統一する。
      * 保存時は `date_format` を指定せず、ISO 8601準拠（Pandas標準）で保存する。

## 4\. ファイル構成イメージ

`src/realtrade/rakuten/rakuten_data.py` (抜粋イメージ)

```python
class RakutenData(bt.feeds.PandasData):
    params = (
        # ...
        ('save_file', None), # 新規パラメータ
    )

    def __init__(self):
        # ...
        self._new_bars = []
        self.save_file = self.p.save_file

    def _load(self):
        # ... (Tick処理)
        completed_bar = self.builder.add_tick(...)
        if completed_bar:
            self._new_bars.append(completed_bar) # 蓄積
            self._populate_lines_from_dict(completed_bar)
            return True
        # ...

    def save_history(self):
        if not self._new_bars:
            return
        
        try:
            # DataFrame作成
            new_df = pd.DataFrame(self._new_bars)
            # カラム調整...
            
            # 既存読み込み & マージ
            if os.path.exists(self.save_file):
                old_df = pd.read_csv(self.save_file, parse_dates=['datetime'])
                merged_df = pd.concat([old_df, new_df])
                merged_df = merged_df.drop_duplicates(subset='datetime', keep='last')
            else:
                merged_df = new_df

            merged_df.sort_values('datetime', inplace=True)
            
            # 保存
            merged_df.to_csv(self.save_file, index=False)
            logger.info(f"履歴データを保存しました: {self.save_file}")
            self._new_bars = []
            
        except Exception as e:
            logger.error(f"履歴データの保存に失敗: {e}")
```

-----

以上が詳細設計書となります。
ご確認いただき、問題がなければ **４，実装（tmp.pyの生成）** へ進みます。